import os
import subprocess
import whisper
import torch
import warnings
from tkinter import Tk, filedialog
from tqdm import tqdm

# áº¨n cáº£nh bÃ¡o FP16 CPU
warnings.filterwarnings("ignore", message="FP16 is not supported on CPU")

# Má»Ÿ há»™p thoáº¡i chá»n thÆ° má»¥c
root = Tk()
root.withdraw()
folder_path = filedialog.askdirectory(title="Chá»n thÆ° má»¥c chá»©a video")

if not folder_path:
    print("âŒ Báº¡n chÆ°a chá»n thÆ° má»¥c nÃ o.")
    exit()

# Liá»‡t kÃª cÃ¡c video trong thÆ° má»¥c
video_extensions = (".mp4", ".mkv", ".avi", ".mov")
video_files = [f for f in os.listdir(folder_path) if f.lower().endswith(video_extensions)]

if not video_files:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y video trong thÆ° má»¥c.")
    exit()

print(f"ğŸ“‚ ThÆ° má»¥c: {folder_path}")
print(f"ğŸï¸ TÃ¬m tháº¥y {len(video_files)} video:")

for idx, v in enumerate(video_files, 1):
    print(f"   {idx}. {v}")

# Check GPU/CPU
if torch.cuda.is_available():
    device = "cuda"
    fp16 = True
    print("\nâš¡ PhÃ¡t hiá»‡n GPU CUDA â†’ sá»­ dá»¥ng FP16 cho tá»‘c Ä‘á»™ nhanh.")
else:
    device = "cpu"
    fp16 = False
    print("\nğŸ¢ KhÃ´ng cÃ³ GPU â†’ cháº¡y CPU (FP32).")

# Load model Whisper
model = whisper.load_model("medium", device=device)

def extract_audio(video_path, audio_path="temp_audio.wav"):
    """TrÃ­ch xuáº¥t audio tá»« video báº±ng ffmpeg"""
    command = ["ffmpeg", "-y", "-i", video_path, "-ar", "16000", "-ac", "1", "-f", "wav", audio_path]
    subprocess.run(command, check=True)

def generate_subtitles(video_path, output_srt, output_txt):
    """Sinh phá»¥ Ä‘á» tá»« video vÃ  táº¡o file txt"""
    audio_path = "temp_audio.wav"
    extract_audio(video_path, audio_path)

    print("ğŸ”Š Äang transcribe báº±ng Whisper ...")

    # Transcribe
    result = model.transcribe(audio_path, fp16=fp16, verbose=False)
    os.remove(audio_path)

    segments = result["segments"]

    # Progress bar cho quÃ¡ trÃ¬nh ghi file
    with tqdm(total=len(segments), desc="âœï¸ Ghi phá»¥ Ä‘á»", ncols=80) as pbar:
        # Ghi file SRT
        with open(output_srt, "w", encoding="utf-8") as f_srt, \
             open(output_txt, "w", encoding="utf-8") as f_txt:

            for i, segment in enumerate(segments, start=1):
                start = segment["start"]
                end = segment["end"]
                text = segment["text"].strip()

                # Format time cho SRT
                def format_time(t):
                    h, m = divmod(t, 3600)
                    m, s = divmod(m, 60)
                    ms = (s - int(s)) * 1000
                    return f"{int(h):02}:{int(m):02}:{int(s):02},{int(ms):03}"

                # Ghi vÃ o .srt
                f_srt.write(f"{i}\n{format_time(start)} --> {format_time(end)}\n{text}\n\n")

                # Ghi vÃ o .txt (chá»‰ ná»™i dung)
                f_txt.write(text + "\n")

                pbar.update(1)


# Xá»­ lÃ½ tá»«ng video
for idx, video in enumerate(video_files, 1):
    video_path = os.path.join(folder_path, video)
    output_srt = os.path.splitext(video_path)[0] + ".srt"
    output_txt = os.path.splitext(video_path)[0] + ".txt"

    print(f"\nğŸ”„ [{idx}/{len(video_files)}] Äang xá»­ lÃ½: {video} ...")
    try:
        generate_subtitles(video_path, output_srt, output_txt)
        print(f"âœ… HoÃ n thÃ nh: {output_srt}, {output_txt}")
    except Exception as e:
        print(f"âŒ Lá»—i vá»›i {video}: {e}")

print("\nğŸ‰ Xong toÃ n bá»™!")
