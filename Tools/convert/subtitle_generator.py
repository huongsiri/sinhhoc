import os
import subprocess
import whisper
import torch
import warnings
from tkinter import Tk, filedialog

# áº¨n cáº£nh bÃ¡o FP16 trÃªn CPU
warnings.filterwarnings("ignore", message="FP16 is not supported on CPU")

# Má»Ÿ há»™p thoáº¡i chá»n thÆ° má»¥c
root = Tk()
root.withdraw()
folder_path = filedialog.askdirectory(title="Chá»n thÆ° má»¥c chá»©a video")

if not folder_path:
    print("âŒ Báº¡n chÆ°a chá»n thÆ° má»¥c nÃ o.")
    exit()

# Liá»‡t kÃª cÃ¡c video trong thÆ° má»¥c
video_extensions = (".mp4", ".mkv", ".avi", ".mov")
video_files = [f for f in os.listdir(folder_path) if f.lower().endswith(video_extensions)]

if not video_files:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y video trong thÆ° má»¥c.")
    exit()

print(f"ğŸ“‚ ThÆ° má»¥c: {folder_path}")
print(f"ğŸï¸ TÃ¬m tháº¥y {len(video_files)} video:")

for idx, v in enumerate(video_files, 1):
    print(f"   {idx}. {v}")

# Check GPU/CPU
if torch.cuda.is_available():
    device = "cuda"
    fp16 = True
    print("\nâš¡ PhÃ¡t hiá»‡n GPU CUDA â†’ sá»­ dá»¥ng FP16 cho tá»‘c Ä‘á»™ nhanh.")
elif torch.backends.mps.is_available():
    device = "mps"
    fp16 = False
    print("\nğŸ PhÃ¡t hiá»‡n Apple Silicon â†’ dÃ¹ng MPS (FP32).")
else:
    device = "cpu"
    fp16 = False
    print("\nğŸ¢ KhÃ´ng cÃ³ GPU â†’ cháº¡y CPU (FP32).")

# Load model Whisper
model = whisper.load_model("medium", device=device)

def extract_audio(video_path, audio_path="temp_audio.wav"):
    """TrÃ­ch xuáº¥t audio tá»« video báº±ng ffmpeg"""
    command = [
        "ffmpeg", "-y", "-hide_banner", "-loglevel", "error",
        "-i", video_path, "-ar", "16000", "-ac", "1", "-f", "wav", audio_path
    ]
    subprocess.run(command, check=True)

def generate_subtitles(video_path, output_srt):
    """Sinh phá»¥ Ä‘á» tá»« video"""
    audio_path = "temp_audio.wav"
    extract_audio(video_path, audio_path)
    result = model.transcribe(audio_path, fp16=fp16)
    os.remove(audio_path)

    # Ghi file SRT
    with open(output_srt, "w", encoding="utf-8") as f:
        for i, segment in enumerate(result["segments"], start=1):
            start = segment["start"]
            end = segment["end"]
            text = segment["text"].strip()

            def format_time(t):
                h, m = divmod(t, 3600)
                m, s = divmod(m, 60)
                ms = (s - int(s)) * 1000
                return f"{int(h):02}:{int(m):02}:{int(s):02},{int(ms):03}"

            f.write(f"{i}\n{format_time(start)} --> {format_time(end)}\n{text}\n\n")

# Xá»­ lÃ½ tá»«ng video
for idx, video in enumerate(video_files, 1):
    video_path = os.path.join(folder_path, video)
    output_srt = os.path.splitext(video_path)[0] + ".srt"

    print(f"\nğŸ”„ [{idx}/{len(video_files)}] Äang xá»­ lÃ½: {video} ...")
    try:
        generate_subtitles(video_path, output_srt)
        print(f"âœ… HoÃ n thÃ nh: {output_srt}")
    except Exception as e:
        print(f"âŒ Lá»—i vá»›i {video}: {e}")

print("\nğŸ‰ Xong toÃ n bá»™!")
